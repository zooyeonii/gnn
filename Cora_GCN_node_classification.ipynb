{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f544156",
   "metadata": {},
   "source": [
    "## Reference : cs224w GCN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d767894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5dab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(CustomConv(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        \n",
    "        for i in range(2):\n",
    "            self.convs.append(CustomConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "   \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "            x = torch.ones(data.num_nodes, 1)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.post_mp(x)\n",
    "    \n",
    "        return emb, F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4205099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation. # mean, max 등등\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        #self.lin_self = nn.Linear(in_channels, out_channels) # convolution\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Convolution을 위해서는 2가지가 필수적임.\n",
    "        x has shape [N, in_channels] # feature matrix\n",
    "        edge_index has shape [2, E] ==> connectivity ==> 2: (u, v)\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Add self-loops to the adjacency matrix. (A+I)\n",
    "        # pyg_utils.add_self_loops(edge_index, num_nodes = x.size(0))  \n",
    "        # neighbor 정보뿐만 아니라, 내 정보까지 add해야하므로 self-loops 추가! \n",
    "        \n",
    "        # 지울수도 있다 !\n",
    "        edge_index, _ = pyg_utils.add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        #self_x = self.lin_self(x) # B\n",
    "        x = self.lin(x) # W\n",
    "        \n",
    "        \n",
    "        # self_x: skip connection #compute message for all the nodes\n",
    "        return self.propagate(edge_index, \n",
    "                                    size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, size):\n",
    "        # Compute messages\n",
    "        # x_i is self-embedding\n",
    "        # x_j has shape [E, out_channels] neighbor embedding\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return x_j\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        F.normalize(aggr_out, p=2, dim=-1) # dim: 상황에 따라 알맞게 조정할 \n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fcc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset):\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(200):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "\n",
    "            emb, pred = model(batch)\n",
    "            label = batch.y \n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            \n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(loader.dataset)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81611123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation = False):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "            \n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        pred = pred[mask]\n",
    "        label = data.y[mask]\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        \n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.test_mask).item()\n",
    "    \n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf23e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.6875. Test accuracy: 0.1580\n",
      "Epoch 10. Loss: 1.3669. Test accuracy: 0.5860\n",
      "Epoch 20. Loss: 0.9079. Test accuracy: 0.6340\n",
      "Epoch 30. Loss: 0.6527. Test accuracy: 0.7010\n",
      "Epoch 40. Loss: 0.3722. Test accuracy: 0.6870\n",
      "Epoch 50. Loss: 0.2494. Test accuracy: 0.6670\n",
      "Epoch 60. Loss: 0.4162. Test accuracy: 0.6620\n",
      "Epoch 70. Loss: 0.4672. Test accuracy: 0.6830\n",
      "Epoch 80. Loss: 0.1396. Test accuracy: 0.6890\n",
      "Epoch 90. Loss: 0.1288. Test accuracy: 0.6750\n",
      "Epoch 100. Loss: 0.0905. Test accuracy: 0.6840\n",
      "Epoch 110. Loss: 0.1545. Test accuracy: 0.6850\n",
      "Epoch 120. Loss: 0.0507. Test accuracy: 0.7070\n",
      "Epoch 130. Loss: 0.0668. Test accuracy: 0.6710\n",
      "Epoch 140. Loss: 0.0416. Test accuracy: 0.7100\n",
      "Epoch 150. Loss: 0.0260. Test accuracy: 0.7150\n",
      "Epoch 160. Loss: 0.0555. Test accuracy: 0.7070\n",
      "Epoch 170. Loss: 0.0211. Test accuracy: 0.6610\n",
      "Epoch 180. Loss: 0.1674. Test accuracy: 0.6990\n",
      "Epoch 190. Loss: 0.0153. Test accuracy: 0.6830\n",
      "GNNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): CustomConv(\n",
      "      (lin): Linear(in_features=1433, out_features=32, bias=True)\n",
      "    )\n",
      "    (1): CustomConv(\n",
      "      (lin): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (2): CustomConv(\n",
      "      (lin): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (lns): ModuleList(\n",
      "    (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (post_mp): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): Dropout(p=0.25, inplace=False)\n",
      "    (2): Linear(in_features=32, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='cora')\n",
    "\n",
    "model = train(dataset)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59eba28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt",
   "language": "python",
   "name": "tt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
